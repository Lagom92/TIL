{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. 딥러닝 원리-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1943년 워랜 맥컬록과 월터 피츠는 처음으로 간소화된 뇌의 뉴런 개념을 발표\n",
    "\n",
    "- 이를 **맥컬록-피츠 뉴런(MCP)**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "- 1957년 프랭크 로젠 블렛은 MCP 뉴런 모델을 기반으로 퍼셉트론 학습 개념을 발표\n",
    "\n",
    "- 자동으로 최적의 가중치를 학습하는 알고리즘을 제안\n",
    "\n",
    "- 가중치: 뉴런의 출력 신호를 낼지 말지를 결정하기 위해 입력 특성에 곱하는 계수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 헵의 학습 규칙\n",
    "\n",
    "- Donald O. Hebb\n",
    "\n",
    "- 인간두뇌의 작용은 개별 신경세포에 의해서 이뤄지는 것이 아닌, 그들간의 연결 강도로 정해진다.\n",
    "\n",
    "- 우리의 두뇌가 신경망으로 활동하고 있음을 설명\n",
    "\n",
    "- 만약 시냅스(축상의 끝)가 양쪽 뉴런이 동시에 또 반복적으로 활성화되었다면 그 뉴런 사이의 연결 강도가 강화된다는 관찰에 근거함\n",
    "\n",
    "- 헵의 학습 규칙은 이후 신경망 모델들의 학습 규칙에 토대가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구성\n",
    "\n",
    "- Input layer\n",
    "\n",
    "- Hidden layers\n",
    "\n",
    "- Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 활성화 함수: 뉴런의 출력값을 정하는 함수\n",
    "\n",
    "- 가중치\n",
    "\n",
    "    - 뉴런에서 학습할때 변한는것은 가중치\n",
    "\n",
    "    - 처음에 초기화를 통해 무작위값을 할당\n",
    "\n",
    "    - 학습과정에서 점차 일정한 값으로 수렴\n",
    "\n",
    "- 학습이 잘된다는것?\n",
    "\n",
    "    - 좋은 가중치를 얻어 원하는 출력에 점점 가까워지는 값을 얻는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.2.0'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.set_random_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "y = 0\n",
    "w = tf.random.normal([1], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수_시그모이드\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.47477188589261"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "output = sigmoid(x*w)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "학습 횟수:  99 Error:  -0.10010598284299604 예측 결과:  0.10010598284299604\n학습 횟수:  199 Error:  -0.05178399422833116 예측 결과:  0.05178399422833116\n학습 횟수:  299 Error:  -0.034590451977903586 예측 결과:  0.034590451977903586\n학습 횟수:  399 Error:  -0.02588962752851373 예측 결과:  0.02588962752851373\n학습 횟수:  499 Error:  -0.020658699939863617 예측 결과:  0.020658699939863617\n학습 횟수:  599 Error:  -0.017174253993457355 예측 결과:  0.017174253993457355\n학습 횟수: 699 Error:  -0.014689506449480992 예측 결과:  0.014689506449480992\n학습 횟수:  799 Error:  -0.012829497265431342 예측 결과:  0.012829497265431342\n학습 횟수:  899 Error:  -0.011385568271837804 예측 결과:  0.011385568271837804\n학습 횟수:  999 Error:  -0.010232493309882492 예측 결과:  0.010232493309882492\n"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    output = sigmoid(x*w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "\n",
    "    if i % 100 == 99:\n",
    "        print(\"학습 횟수: \", i, \"Error: \", error, \"예측 결과: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- error = 기대 출력 - 실제 출력\n",
    "\n",
    "- 경사하강법\n",
    "\n",
    "    w = w + * η * error\n",
    "\n",
    "    - η(학습률): 가중치 조정을 위한 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "학습 횟수:  99 Error:  0.5 예측 결과:  0.5\n학습 횟수:  199 Error:  0.5 예측 결과:  0.5\n학습 횟수:  299 Error:  0.5 예측 결과:  0.5\n학습 횟수:  399 Error:  0.5 예측 결과:  0.5\n학습 횟수:  499 Error:  0.5 예측 결과:  0.5\n학습 횟수: 599 Error:  0.5 예측 결과:  0.5\n학습 횟수:  699 Error:  0.5 예측 결과:  0.5\n학습 횟수:  799 Error:  0.5 예측 결과:  0.5\n학습 횟수:  899 Error:  0.5 예측 결과:  0.5\n학습 횟수:  999 Error:  0.5 예측 결과:  0.5\n"
    }
   ],
   "source": [
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x*w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "\n",
    "    if i % 100 == 99:\n",
    "        print(\"학습 횟수: \", i, \"Error: \", error, \"예측 결과: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 코드의 경우 입력에 0이 들어가 버리면서 가중치 조정이 되지 않았다.\n",
    "\n",
    "- 이런한 경우를 방지하고자 편향이라는 개념이 등장했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 편향\n",
    "\n",
    "- 입력으로는 늘 한쪽으로 치우쳐진 고정값\n",
    "\n",
    "- 입력으로 받은 값이 0인 경우에 아무것도 학습하지 못하는 것을 방지\n",
    "\n",
    "- 가중치처럼 난수로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "학습 횟수:  99 Error:  0.11238258794086264 예측 결과:  0.8876174120591374\n학습 횟수:  199 Error:  0.055071863836639534 예측 결과:  0.9449281361633605\n학습 횟수:  299 Error:  0.036054548409353404 예측 결과:  0.9639454515906466\n학습 횟수:  399 Error:  0.026708631840398844 예측 결과:  0.9732913681596012\n학습 횟수:  499 Error:  0.02117969038866041 예측 결과:  0.9788203096113396\n학습 횟수: 599 Error:  0.017534051963307373 예측 결과:  0.9824659480366926\n학습 횟수:  699 Error:  0.01495259801362292 예측 결과:  0.9850474019863771\n학습 횟수:  799 Error:  0.013030120422014457 예측 결과:  0.9869698795779855\n학습 횟수:  899 Error:  0.011543493497685131 예측 결과:  0.9884565065023149\n학습 횟수: 999 Error:  0.01036000375513546 예측 결과:  0.9896399962448645\n"
    }
   ],
   "source": [
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x*w+1*b)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    b = b + 1 * 0.1 * error\n",
    "\n",
    "    if i % 100 == 99:\n",
    "        print(\"학습 횟수: \", i, \"Error: \", error, \"예측 결과: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론을 잘 이해하는 방법은 인공지능의 겨울을 불러왔던 AND OR XOR에 대해 아는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND OR XOR\n",
    "### logic gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND 연산\n",
    "\n",
    "- 입력이 모두 참인 경우에만 참을 출력 한다.\n",
    "\n",
    "- 나머지의 경우에 대해서는 모두 거짓을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X:  [1 1] Y:  [1] Output:  0.9644456297910021\nX:  [1 0] Y:  [0] Output:  0.025192749680225585\nX:  [0 1] Y:  [0] Output:  0.02527072813932697\nX:  [0 0] Y:  [0] Output:  2.4699881769426642e-05\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [0], [0], [0]])\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j]*w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "\n",
    "for i in range(4):\n",
    "    print('X: ', x[i], 'Y: ', y[i], 'Output: ', sigmoid(np.sum(x[i]*w) + b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR 연산\n",
    "\n",
    "- 모든 입력값이 거짓일 때만 거짓을 출력한다.\n",
    "\n",
    "- 입력 중에 하나라도 참이면 참을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X:  [1 1] Y:  [0] Output:  0.0357423918171506\nX:  [1 0] Y:  [1] Output:  0.9746750685199782\nX:  [0 1] Y:  [1] Output:  0.9745963492216262\nX:  [0 0] Y:  [1] Output:  0.9999748962032539\n"
    }
   ],
   "source": [
    "# AND 연산과 출력값이 다름\n",
    "# 다른 코드는 AND연산 코드와 동일\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [1]])\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j]*w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "\n",
    "for i in range(4):\n",
    "    print('X: ', x[i], 'Y: ', y[i], 'Output: ', sigmoid(np.sum(x[i]*w) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR 연산\n",
    "\n",
    "- 2개의 입력값이 서로 다를 때 참을 출력한다.\n",
    "\n",
    "- ex)\n",
    "\n",
    "    - 참 + 참 = 거짓\n",
    "\n",
    "    - 참 + 거짓 = 참\n",
    "\n",
    "    - 거짓 + 참 = 참\n",
    "    \n",
    "    - 거짓 + 거짓 = 거짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X:  [1 1] Y:  [0] Output:  0.5128176286712095\nX:  [1 0] Y:  [1] Output:  0.5128176305326305\nX:  [0 1] Y:  [1] Output:  0.4999999990686774\nX:  [0 0] Y:  [0] Output:  0.5000000009313226\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j]*w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "\n",
    "for i in range(4):\n",
    "    print('X: ', x[i], 'Y: ', y[i], 'Output: ', sigmoid(np.sum(x[i]*w) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 결과값이 0.5 근처에 머물며 원하는 값으로 수렴하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해결책\n",
    "\n",
    "- 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI WINTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다층 퍼셉트론의 약점\n",
    "\n",
    "    - 파리머터의 개수가 많아지면서 적절한 가중치와 편향을 학습하는 것이 어렵다는 것\n",
    "\n",
    "- 제프리 힌튼은 역전파 알고리즘을 제시하며 문제를 해결함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "--------------------------\n",
    "\n",
    "### 퀴즈\n",
    "\n",
    "1. 1957년, 프랭크 로젠블랫은 맥컬록-피츠 모델(MCP)을 기반으로 _ _ _ _ _ _ _ _ _ _ 개념을 발표했다. (영문 소문자로 적어주세요.)\n",
    "\n",
    "    답: perceptron\n",
    "\n",
    "2. 경사하강법에서 가중치 조정을 위한 하이퍼파라미터로써 어떻게 설정하느냐에 따라 학습 시간이 달라지는 이것은 무엇인가? _ _ _\n",
    "\n",
    "    답: 학습률\n",
    "\n",
    "3. 단층 퍼셉트론으로 AND, OR, XOR 문제를 모두 해결 할 수 있다.\n",
    "\n",
    "    답: X\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitd6c49ce9a0fb4da9a60aa5dde01a050b",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}