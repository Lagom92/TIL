# 6. 머신러닝을 위한 기초 수학-2

<br/>

- Noisy Data

<br/>

- y = ax + b
  - a: 기울기
  - b: 절편

<br/>

- `θ` (theta) = 통계학에서 미지수나 추정값을 표현하는 방법

<br/>

- y = θ_0 + θ_1 x

<br/>

- 머신러닝의 핵심
  - 과거의 관측을 기반으로 새로운 샘플의 결과값을 예측

<br/>

- 우리가 바라는 이상
  - 적합한 파라미터(parameter)
  - 즉, 적합한 가중치와 절편 탐색
  - 그 파라미터를 통해 실제 결과값과 예측 결과값의 차이를 찾아 0을 만드는 것
  - 실제값과 예측값의 차이가 0 이 되도록

<br/>

- 완전 딱 맞는 모델은 현실성이 떨어진다.

<br/>

- 우리의 목표

  - 모든 점에서 생기는 오차의 합계가 가능한 작아지는 함수를 찾는 것

  - 오차의 합계를 알려주는 식

    - 어떠한 목적을 가지고 있다 라고 하여 **목적 함수**라고 부른다.

    - $$
      E(θ) = \frac{1}{2} \sum_{i=1}^{n} ((y^{(i)} - \hat{y}^{(i)}))^2
      $$

<br/>

- 최적화 문제
  - 목적 함수 값이 가장 작아지는 파라미터들을 찾는 것

<br/>

- 제곱을 하는 이유

  - 음수와 양수의 상쇄로 문제가 발생 할 수 있음

  - 그러므로 제곱을 하여 양수로 만들어줌
  - 오차가 클수록 더 크게 인식되는 효과도 얻을 수 있다.

<br/>

- 목적 함수에 1/2 이 있는 이유 
  - 미분과 연관 있다.
  - 결과로 나온 식을 간단한 모양으로 만들기 위한 상수



<br/>

<br/>

### 경사 하강법

목적함수의 값을 최소화 시키기 위해 마치 경사를 내려가듯 최소값을 찾는 기법

<br/>

- 미분
  - 어떤 구간에서의 그래프의 기울기를 구하는 것

<br/>

- 미분 연산자: d

<br/>

- 미분 공식
  $$
  \frac{d}{dx} f(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}
  $$
  <br/>
  $$
  f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}
  $$

<br/>

- 미분의 성질

$$
\frac{d}{dx}a = (a =상수)
$$

<br/>
$$
\frac{d}{dx}f(x) = n x^{n-1}
$$
<br/>
$$
\frac{d}{dx} x = \frac{d}{dx} x^1 = 1 \times x^0 = 1
$$
<br/>
$$
\frac{d}{dx} x^3 = 3x^2
$$
<br/>
$$
\frac{d}{dx} x ^{-2} = -2x^{-3}
$$
<br/>
$$
\frac{d}{dx}10x^4 = 10\frac{d}{dx}x^4 = 10 \times 4x^3 = 40x^3
$$
<br/>

- 도함수: 함수를 미분한 식

  - $$
    \frac{d}{dx} g(x)
    $$

<br/>

- 임의의 2차함수 그래프가 있을때, 도함수의 부호 반대 방향으로 밀어 옮기면 자연스럽게 최소값 쪽으로 움직인다.

<br/>

- 경사 하강법

$$
x := x - η \frac{d}{dx} g(x)
$$

<br/>

- `A := B` : A를 B에 따라 정의한다는 의미

<br/>

- 학습률(`η`)
  - 에타
  - 양의 정수
  - 학습률에 따라 최소값에 도달하기까지 갱신해야 하는 회수가 달라진다.
  - 수렴되는 속도가 달라진다고 표현한다.
  - 학습률이 너무 크면 발산이 발생한다.
  - 학습률이 너무 작으면 최소값에 수렴하기 까지 너무 많은 시간이 걸린다.
  - 학습률은 머신러닝의 실험적 성격으로 정답은 없다.



<br/>

<br/>

### 퀴즈

1. 표준편차가 7인 데이터의 분산을 구하시오.

   답: 49

<br/>

2. 함수 기울기를 낮은 쪽으로 계속 이동시켜서 극값에 이를 때까지 반복시키는 것으로 학습을 통해 모델의 최적 파라미터를 찾는 것이 목표인 이 방법은 무엇인가? (5글자)

   답: 경사하강법





<br/><br/>