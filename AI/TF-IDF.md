# TF-IDF

### TermFrequency - Inverse Document Frequency



<br/>

### 개념

- TF(단어빈도, Term Frequency)

  - 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값
  - 이 값이 높을수록 문서에서 중요하다.
  - 하지만, 하나의 문서에서 많이 나오지 않고 다른 문서에서 자주 등장하면 단어의 중요도는 낮아진다.

  <br/>

- DF(문서빈도, Document Frequency)

  - 특정 단어가 나타나는 문서의 수

  <br/>

- IDF(역문서 빈도, Inverse Document Frequency)

  - DF에 일종의 역수변환을 해준 값
  - IDF 수식은 idf_smoothing 여부에 따라 다라진다.

  <br/>

- TF-IDF

  - TF와 IDF를 곱한 값
  - 점수가 높은 단어일수록 다른 문서에서는 많지 않고 해당 문서에서 자주 등장하는 단어를 의미한다.



<br/>

### 사용하는 이유

TF-IDF는 특징 추출(Feature extraction) 기법

머신러닝, 딥러닝 학습 시에 변수들을 만들 때, 텍스트 데이터의 특징을 담아서 학습을 시켜줘야 하기 때문에 이런 특징추출 기법이 사용된다.

- 단어의 빈도수를 기반으로 특징을 추출하는 방법
  - CountVectorizer
  - 조사와 관사처럼 많이 등장하는 단어들을 중요하다 생각하기 때문에 유의미한 결과를 얻기 힘들 수 있다.

- 위의 단점을 해결한것
  - TF-IDF
  - 여러 문서에서 많이 등장하는 단어들에게 일종의 패널티를 주는 것
  - TF가 가산점이면, IDF는 패널티로서 TF-IDF = TF * IDF 라는 수식이 이뤄진다.



<br/>

### 명제

특정 단어의 중요도는 단어가 출현한 횟수에 비례하고 그 단어가 언급된 모든 문서의 총수에 반비례한다.



<br/>

### 수식

$$
ln({1+n \over 1+df}) + 1
$$



<br/>

### 목적

다른 문서에 자주 언급되지 않고 해당 문서에는 자주 언급되는 단어에 대해 점수를 높게 부여하는 것



<br/>

### 포인트

특정 단어가 해당 문서에서는 자주 나오지만 다른 문서에서는 자주 나오지 않는다면, 이 단어는 중요한 단어이다.

(ex) 특정 이름이나 명사의 경우에는 A문서에서만 자주 나오고 B문서에서는 자주 나오지 않는다. 즉 그 특정 이름이나 명사가 중요한 단어라는 것이다. 하지만 조사나 관사의 경우에는 A문서 뿐만 아니라 B문서에서도 많이 나올 수 있다. 그러면 이 것의 중요도는 낮다고 판단할 수 있다.)



<br/>

## TF-IDF 구현

Scikit-Learn 라이브러리를 이용해 구현하기

- TF-IDF jupyter notebook 를 참고





### Reference

 https://chan-lab.tistory.com/24 

 https://chan-lab.tistory.com/27 

