{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF \n",
    "## TermFrequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF 개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['I go to my home my home is very large', \n",
    "        'I went out my home I go to the market', \n",
    "        'I bought a yellow lemon I go back to home'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer().fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'go': 2, 'to': 11, 'my': 8, 'home': 3, 'is': 4, 'very': 12, 'large': 5, 'went': 13, 'out': 9, 'the': 10, 'market': 7, 'bought': 1, 'yellow': 14, 'lemon': 6, 'back': 0}\n",
      "[('back', 0), ('bought', 1), ('go', 2), ('home', 3), ('is', 4), ('large', 5), ('lemon', 6), ('market', 7), ('my', 8), ('out', 9), ('the', 10), ('to', 11), ('very', 12), ('went', 13), ('yellow', 14)]\n"
     ]
    }
   ],
   "source": [
    "# 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "# 보기 좋게 정렬\n",
    "print(sorted(tfidf_vectorizer.vocabulary_.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TF, DF, IDF 벡터화 과정의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "        0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "        0.        , 0.2170186 , 0.36744443, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.24902824, 0.24902824, 0.        ,\n",
       "        0.        , 0.        , 0.42164146, 0.3206692 , 0.42164146,\n",
       "        0.42164146, 0.24902824, 0.        , 0.42164146, 0.        ],\n",
       "       [0.44514923, 0.44514923, 0.26291231, 0.26291231, 0.        ,\n",
       "        0.        , 0.44514923, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26291231, 0.        , 0.        , 0.44514923]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text로 부터 각 단어의 빈도 수를 기록한다.\n",
    "tfidf_vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF 벡터화 내부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "DF_vec = np.array([1, 1, 3, 3, 1,\n",
    "                  1, 1, 1, 2, 1,\n",
    "                  1, 3, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수식\n",
    "\n",
    "$$\n",
    "ln({1+n \\over 1+df}) + 1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_func(n, df):\n",
    "    rst = np.log((1 + n)/(1 + df)) + 1\n",
    "    \n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "idf_func(n, DF_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 함수와 위의 idf의 값이 같음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TF-IDF 벡터화 내부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "        0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "        0.        , 0.2170186 , 0.36744443, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.24902824, 0.24902824, 0.        ,\n",
       "        0.        , 0.        , 0.42164146, 0.3206692 , 0.42164146,\n",
       "        0.42164146, 0.24902824, 0.        , 0.42164146, 0.        ],\n",
       "       [0.44514923, 0.44514923, 0.26291231, 0.26291231, 0.        ,\n",
       "        0.        , 0.44514923, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26291231, 0.        , 0.        , 0.44514923]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = np.array([\n",
    "    0, 0, 1, 2, 1,\n",
    "    1, 0, 0, 2, 0,\n",
    "    0, 1, 1, 0, 0\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬의 곱 X\n",
    "- 각각의 곱셈을 해야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 1.        , 2.        , 1.69314718,\n",
       "       1.69314718, 0.        , 0.        , 2.57536414, 0.        ,\n",
       "       0.        , 1.        , 1.69314718, 0.        , 0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(count_vec, tfidf_vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 정규화가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tf_idf_before_L2 = np.multiply(count_vec, tfidf_vectorizer.idf_)\n",
    "tf_idf_before_L2 = tf_idf_before_L2.reshape(1, -1)\n",
    "tf_idf_after_L2 = preprocessing.normalize(tf_idf_before_L2, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "        0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "        0.        , 0.2170186 , 0.36744443, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_after_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python37664bitnlpconda2e37df55ef7041bb8d56bf0ba20910ea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
